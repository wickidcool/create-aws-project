---
phase: 13-reporting-local-runner
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/__tests__/harness/local-runner.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "npm run test:e2e executes validation suite and returns exit code"
    - "Progress shows 'Testing X/N: config-name' for each configuration"
    - "Failed validations display stdout/stderr immediately after failure"
    - "Summary table at end shows config name, status, failed step, and duration"
  artifacts:
    - path: "src/__tests__/harness/local-runner.ts"
      provides: "Validation runner with spinner progress and summary output"
      exports: ["runValidationSuite"]
      min_lines: 80
    - path: "package.json"
      provides: "npm scripts for E2E validation"
      contains: "test:e2e"
  key_links:
    - from: "src/__tests__/harness/local-runner.ts"
      to: "fixtures/index.js"
      via: "import getConfigsByTier"
      pattern: "import.*getConfigsByTier.*from.*fixtures"
    - from: "src/__tests__/harness/local-runner.ts"
      to: "validate-project.js"
      via: "import validateGeneratedProject"
      pattern: "import.*validateGeneratedProject.*from.*validate-project"
    - from: "package.json"
      to: "src/__tests__/harness/local-runner.ts"
      via: "node --import tsx/esm"
      pattern: "test:e2e.*local-runner"
---

<objective>
Create local validation runner with real-time progress reporting and npm script integration

Purpose: Enable developers to run full validation suite locally with clear feedback on progress and failures, satisfying requirements REPT-01, REPT-02, REPT-04, REPT-05.

Output:
- `src/__tests__/harness/local-runner.ts` - Validation runner with ora spinner progress
- Updated `package.json` with test:e2e npm scripts
</objective>

<execution_context>
@/Users/alwick/.claude/get-shit-done/workflows/execute-plan.md
@/Users/alwick/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-reporting-local-runner/13-RESEARCH.md

# Prior phase artifacts
@src/__tests__/harness/fixtures/index.ts
@src/__tests__/harness/fixtures/matrix.ts
@src/__tests__/harness/validate-project.ts
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create local runner with spinner progress and summary table</name>
  <files>src/__tests__/harness/local-runner.ts</files>
  <action>
Create the local validation runner following patterns from 13-RESEARCH.md:

1. **Imports:** ora for spinner, picocolors (pc) for colors, getConfigsByTier and TestTier from fixtures, validateGeneratedProject and ValidationResult from validate-project

2. **CI detection:** Detect CI environment (`process.env.CI === 'true' || !process.stdout.isTTY`). When in CI, disable ora spinner - use simple console.log for progress updates instead. This prevents ANSI escape code pollution in CI logs.

3. **runValidationSuite(tier: TestTier = 'core'):**
   - Get configs via `getConfigsByTier(tier)`
   - Print header: "Running N validation tests (tier: X)"
   - For each config (indexed 0 to N-1):
     - Show progress: "Testing {i+1}/{N}: {config.name}"
     - If TTY: use `spinner.start(progress)`, update with `spinner.succeed()` or `spinner.fail()`
     - If CI: use `console.log(progress)`, then `console.log('PASS: ...')` or `console.error('FAIL: ...')`
     - Call `validateGeneratedProject(config.config)`
     - On success: show green checkmark
     - On failure: show red X with "(failed at {result.failedStep})", then immediately display error output with colored delimiters:
       ```
       --- Error Output ---
       {failedStep.output}
       --- End Error Output ---
       ```
   - Store all results in array

4. **displaySummary(results, configs):**
   - Build rows array with: config name, status (checkmark/X PASS/FAIL), failedStep or '-', duration in seconds
   - Print "=== Validation Summary ===" header
   - Use `console.table(rows)` for formatted output
   - Print "Results: X/N passed (P%)"

5. **Exit handling:**
   - After summary, check `results.every(r => r.success)`
   - Call `process.exit(0)` if all passed, `process.exit(1)` if any failed

6. **CLI entry point:**
   - Parse `process.argv[2]` as tier argument (default: 'core')
   - Validate tier is 'smoke' | 'core' | 'full' (log error and exit 1 if invalid)
   - Call `runValidationSuite(tier)`

7. **Error handling:**
   - Wrap main loop in try-catch
   - On exception: stop spinner, log error, push failed result, continue to next config
   - Spinner cleanup in finally block

Key patterns from research:
- Use `i + 1` for display (1-indexed), `i` for array access (0-indexed)
- Display error output IMMEDIATELY after failure (not batched at end)
- Keep summary table columns narrow (no long error messages in table)
- Colors as enhancement, symbols for accessibility (checkmark/X)
  </action>
  <verify>
1. TypeScript compiles without errors: `npm run build`
2. File exists with correct exports: `grep -l "runValidationSuite" src/__tests__/harness/local-runner.ts`
3. Imports ora, picocolors, fixtures, validate-project: `grep -E "(import.*ora|import.*picocolors|import.*fixtures|import.*validate-project)" src/__tests__/harness/local-runner.ts`
  </verify>
  <done>
- local-runner.ts exists with runValidationSuite function
- Imports ora, picocolors, fixtures, and validate-project modules
- TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Add npm scripts and verify end-to-end execution</name>
  <files>package.json</files>
  <action>
Add npm scripts for E2E validation to package.json:

1. **Add scripts:**
   ```json
   "test:e2e": "node --import tsx/esm src/__tests__/harness/local-runner.ts",
   "test:e2e:smoke": "node --import tsx/esm src/__tests__/harness/local-runner.ts smoke",
   "test:e2e:full": "node --import tsx/esm src/__tests__/harness/local-runner.ts full"
   ```

2. **Script placement:** Add after existing test scripts (test, test:watch, test:coverage), before lint scripts

3. **tsx dependency check:** tsx is NOT in devDependencies. Add it:
   ```bash
   npm install --save-dev tsx
   ```
   This enables TypeScript execution via `--import tsx/esm` loader

4. **Verify scripts work:**
   - Run `npm run test:e2e:smoke` to execute smoke tier (1 config)
   - This validates the entire pipeline: runner -> fixtures -> validate-project -> generation
   - Expected output: spinner progress, pass/fail indicator, summary table
   - Note: This will take several minutes as it generates a project and runs npm install/build/test
  </action>
  <verify>
1. tsx installed: `grep '"tsx"' package.json`
2. Scripts exist: `grep 'test:e2e' package.json`
3. Smoke tier runs (may take ~5 minutes): `timeout 600 npm run test:e2e:smoke`
   - If validation passes: exit code 0, summary shows "1/1 passed"
   - If validation fails: exit code 1, error output displayed, summary shows failure
  </verify>
  <done>
- tsx devDependency added to package.json
- test:e2e, test:e2e:smoke, test:e2e:full scripts added to package.json
- npm run test:e2e:smoke executes and produces progress/summary output
  </done>
</task>

</tasks>

<verification>
All requirements verified:

- **REPT-01** (Failed validations display stdout/stderr): Run smoke with intentionally broken config, verify error output appears immediately after failure indicator
- **REPT-02** (npm run test:e2e): Script exists and executes local-runner.ts
- **REPT-04** (Progress shows config name): Output shows "Testing 1/1: web-api-cognito" format
- **REPT-05** (Summary table): console.table output at end shows all results

Full verification:
```bash
# Verify scripts exist
npm run | grep test:e2e

# Run smoke tier (quick validation)
npm run test:e2e:smoke

# Verify output contains expected elements
# - Progress: "Testing 1/1: web-api-cognito"
# - Summary table with columns
# - Results line: "Results: 1/1 passed"
# - Exit code: 0 (if passed)
```
</verification>

<success_criteria>
1. `npm run test:e2e:smoke` completes and shows progress/summary output
2. Progress displays "Testing X/N: config-name" format
3. Summary table displays at end with pass/fail status
4. Exit code is 0 when all pass, 1 when any fail
5. TypeScript compiles without errors (npm run build)
6. All 118+ existing tests still pass (npm test)
</success_criteria>

<output>
After completion, create `.planning/phases/13-reporting-local-runner/13-01-SUMMARY.md`
</output>
